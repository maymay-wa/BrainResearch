{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MRI Data Processing and Analysis\n",
    "\n",
    "This notebook demonstrates how to set up and use the `DataPipe` class for handling neuroimaging data, from reading subject files to registering images to a common atlas and analyzing volumetric changes.\n",
    "\n",
    "This notebook is for presentation only, and will not run the code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports\n",
    "\n",
    "We start by importing all necessary libraries, including `pandas` and `nibabel` for data handling, `ANTS` for image registration, and `matplotlib`/`nilearn` for plotting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ants\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "from nilearn.plotting import plot_anat, plot_img\n",
    "from nilearn.datasets import fetch_atlas_harvard_oxford\n",
    "from nilearn.image import math_img, resample_to_img, get_data, load_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. The `DataPipe` Class\n",
    "\n",
    "Below is the definition of the `DataPipe` class. It is designed to:\n",
    "\n",
    "- Store and manage file paths and participant information.\n",
    "- Load and process neuroimaging data.\n",
    "- Perform image registration to a common atlas.\n",
    "- Compute volumetric changes and differences across brain regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataPipe:\n",
    "    \"\"\"\n",
    "    Responsibilities:\n",
    "        • Handles subject MRI data.\n",
    "        • Manages file paths and participant info.\n",
    "        • Loads and processes neuroimaging data.\n",
    "        • Performs registration to a common atlas.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1: The `__init__` Method\n",
    "This sets up paths, loads participants, fetches the atlas, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_pipe_init(self, data_dir='Data', participants_tsv='Data/participants.tsv'):\n",
    "        \"\"\"\n",
    "        Constructor for the Data class.\n",
    "        data_dir : str\n",
    "            The root directory containing subject data.\n",
    "        participants_tsv : str\n",
    "            Path to the participants.tsv file.\n",
    "\n",
    "        Key Initialization Steps:\n",
    "        •\tSets the working directory.\n",
    "        •\tStores paths for data and participant information.\n",
    "        •\tLoads a participant DataFrame from a .tsv file.\n",
    "        •\tFetches the Harvard-Oxford Atlas for regional brain analysis.\n",
    "        •\tPrepares additional DataFrame columns to store file paths and volumetric data.\n",
    "        \"\"\"\n",
    "        # Sets the working directory to be where the file is found\n",
    "        script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "        os.chdir(script_dir)\n",
    "        self.data_dir = os.path.abspath(data_dir)\n",
    "        self.participants_tsv = os.path.abspath(participants_tsv)\n",
    "\n",
    "        self.data_dir = data_dir\n",
    "        self.participants_tsv = participants_tsv\n",
    "        # Load participants DataFrame\n",
    "        self.participants_df = pd.read_csv(self.participants_tsv, sep=\"\\t\")\n",
    "        # Fetch atlas upon initialization\n",
    "        self.fetch_harvard_oxford_atlas()\n",
    "        # Prepare columns in participants_df for file paths and volumetric data\n",
    "        self.prepare_dataframe_columns()\n",
    "\n",
    "# Monkey-patch the __init__ method into DataPipe\n",
    "DataPipe.__init__ = data_pipe_init"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2: `fetch_harvard_oxford_atlas`\n",
    "Loads atlas image, region labels, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_harvard_oxford_atlas(self):\n",
    "        \"\"\"\n",
    "        Purpose:\n",
    "        •\tFetches the Harvard-Oxford cortical atlas.\n",
    "        •\tLoads atlas image and extracts region labels.\n",
    "        •\tConverts atlas data into a NumPy array.\n",
    "        •\tHandles exceptions in case the atlas cannot be retrieved.\n",
    "\n",
    "        Key Variables:\n",
    "        •\tATLAS_MAPS: The atlas image.\n",
    "        •\tATLAS_IMAGE: Loaded version of ATLAS_MAPS.\n",
    "        •\tATLAS_DATA: NumPy representation of the atlas.\n",
    "        •\tLABEL_NAMES: Names of brain regions.\n",
    "        •\tREGION_LABELS: Unique region indices.\n",
    "        \"\"\"\n",
    "        # Fetch the Harvard-Oxford atlas\n",
    "        try:\n",
    "            ATLAS = fetch_atlas_harvard_oxford('cort-maxprob-thr25-1mm')\n",
    "            # Load the atlas image\n",
    "            self.ATLAS_MAPS = ATLAS.maps\n",
    "            self.ATLAS_IMAGE = load_img(self.ATLAS_MAPS)\n",
    "            self.ATLAS_DATA = get_data(self.ATLAS_IMAGE)\n",
    "            # Extract region names from the atlas\n",
    "            self.LABEL_NAMES = ATLAS['labels']\n",
    "            # Extract unique region labels from the atlas\n",
    "            self.REGION_LABELS = np.unique(self.ATLAS_DATA)\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error fetching/loading Harvard-Oxford atlas: {e}\")\n",
    "            raise  # In many cases, you'd want to stop execution if the atlas isn't available.\n",
    "\n",
    "DataPipe.fetch_harvard_oxford_atlas = fetch_harvard_oxford_atlas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3: `prepare_dataframe_columns`\n",
    "Adds new columns for file paths and volumetric data per region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataframe_columns(self):\n",
    "        \"\"\"\n",
    "        Purpose:\n",
    "        •\tAdds new columns to the participant DataFrame:\n",
    "        •\tFile paths for MRI images.\n",
    "        •\tVolume calculations per brain region.\n",
    "        •\tChanges in volume between baseline and follow-up scans.\n",
    "\n",
    "        Logic:\n",
    "        •\tCreates empty placeholders for each region’s volumetric data.\n",
    "        •\tUses self.LABEL_NAMES to track which regions to include.\n",
    "        •\tSkips “Background” and “Unknown Region” labels.\n",
    "        \"\"\"\n",
    "        # Prepare the new columns for file paths\n",
    "        file_cols = ['Baseline File Path', 'Followup File Path']\n",
    "        new_cols = {col: [None] * len(self.participants_df) for col in file_cols}\n",
    "        \n",
    "        # Prepare columns for volume and difference metrics for each region\n",
    "        for label in self.LABEL_NAMES:\n",
    "            # Skip background or unknown labels\n",
    "            if label in (\"Background\", \"Unknown Region\"):\n",
    "                continue\n",
    "            new_cols[f\"{label} Volume Avg\"] = [None]*len(self.participants_df)\n",
    "            new_cols[f\"{label} Volume Change\"] = [None]*len(self.participants_df)\n",
    "            new_cols[f\"{label} Change\"] = [None]*len(self.participants_df)\n",
    "\n",
    "        # Create an empty DataFrame and horizontally concatenate\n",
    "        columns_df = pd.DataFrame(new_cols, index=self.participants_df.index)\n",
    "        self.participants_df = pd.concat([self.participants_df, columns_df], axis=1)\n",
    "\n",
    "DataPipe.prepare_dataframe_columns = prepare_dataframe_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4: `get_subject_file_pairs`\n",
    "Locates subject baseline and follow-up files, stores paths in the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subject_file_pairs(self):\n",
    "        \"\"\"\n",
    "        Given a DataFrame of participants and the data directory,\n",
    "        locate subject baseline (BL) and follow-up (FU) files\n",
    "        and store them in the DataFrame columns.\n",
    "\n",
    "        Purpose:\n",
    "        •\tIterates through the data_dir to find subjects.\n",
    "        •\tSearches for baseline (BL) and follow-up (FU) files.\n",
    "        •\tStores file paths in self.participants_df.\n",
    "        \"\"\"\n",
    "        # Iterate through the data directory\n",
    "        for subject_folder in os.listdir(self.data_dir):\n",
    "            subject_path = os.path.join(self.data_dir, subject_folder)\n",
    "            \n",
    "            # Skip non-directories or irrelevant files\n",
    "            if (\n",
    "                not os.path.isdir(subject_path) \n",
    "                or subject_folder.startswith('.') \n",
    "                or subject_folder == 'derivatives'\n",
    "            ):\n",
    "                continue\n",
    "\n",
    "        # Now match participants to BL/FU files\n",
    "        for index, row in self.participants_df.iterrows():\n",
    "            subject = row['participant_id']\n",
    "            subject_path = os.path.join(self.data_dir, f\"sub-{subject:03d}\")\n",
    "            \n",
    "            # Define expected file paths for baseline and follow-up MRI scans\n",
    "            baseline_file = os.path.join(\n",
    "                subject_path, \n",
    "                'ses-BL', \n",
    "                'anat', \n",
    "                f\"sub-{subject:03d}_ses-BL_T1w.nii.gz\"\n",
    "            )\n",
    "            followup_file = os.path.join(\n",
    "                subject_path, \n",
    "                'ses-FU', \n",
    "                'anat', \n",
    "                f\"sub-{subject:03d}_ses-FU_T1w.nii.gz\"\n",
    "            )\n",
    "\n",
    "            # Ensure both files exist before adding them to the DataFrame\n",
    "            if os.path.exists(baseline_file) and os.path.exists(followup_file):\n",
    "                # Add the file paths to the DataFrame\n",
    "                self.participants_df.at[index, 'Baseline File Path'] = (\n",
    "                    'Data/' + os.path.relpath(baseline_file, self.data_dir)\n",
    "                )\n",
    "                self.participants_df.at[index, 'Followup File Path'] = (\n",
    "                    'Data/' + os.path.relpath(followup_file, self.data_dir)\n",
    "                )\n",
    "            else:\n",
    "                print(f\"Skipping subject {subject}: missing files.\")\n",
    "\n",
    "DataPipe.get_subject_file_pairs = get_subject_file_pairs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5: `register_and_convert_to_nifti`\n",
    "Registers a subject’s MRI scan to a reference atlas using ANTs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_and_convert_to_nifti(self, fixed_image, moving_image, subject_id, session, transform_type='Affine'):\n",
    "        \"\"\"\n",
    "        Registers `moving_image` to `fixed_image` using ANTs, writes out the\n",
    "        transformed result to disk as a NIfTI file, and returns the nibabel image.\n",
    "\n",
    "        Purpose:\n",
    "        •\tUses ANTs to register a subject’s MRI scan to a reference (atlas).\n",
    "        •\tSaves the registered image as a NIfTI file.\n",
    "        •\tHandles errors and skips re-registration if output already exists.\n",
    "\n",
    "        Logic:\n",
    "        1.\tCheck if the output file exists.\n",
    "        2.\tApply bias field correction and smoothing.\n",
    "        3.\tPerform image registration using ANTs.\n",
    "        4.\tSave the registered image to disk.\n",
    "        5.\tReturn a nibabel-compatible image.\n",
    "        \"\"\"\n",
    "        out_path = f\"output/registered_output_sub-{subject_id}_ses-{session}.nii.gz\"\n",
    "        \n",
    "        # If the file already exists, load it and skip registration\n",
    "        if os.path.exists(out_path):\n",
    "            try:\n",
    "                file = nib.load(out_path)\n",
    "                return file\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Error loading existing registered image for subject {subject_id}, session {session}: {e}\")\n",
    "                raise\n",
    "        \n",
    "        # Preprocess the moving image (bias field correction + smoothing)\n",
    "        moving_image = ants.n4_bias_field_correction(moving_image)\n",
    "        moving_image = ants.smooth_image(moving_image, 2)\n",
    "\n",
    "        # Registration\n",
    "        try:\n",
    "            outputImage = ants.registration(\n",
    "                fixed=fixed_image,\n",
    "                moving=moving_image,\n",
    "                type_of_transform=transform_type\n",
    "            )['warpedmovout']\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error registering images for subject {subject_id}, session {session}: {e}\")\n",
    "            raise\n",
    "\n",
    "        # Write out the registered result\n",
    "        ants.image_write(outputImage, out_path)\n",
    "        \n",
    "        # Load the resulting file as a nibabel image\n",
    "        try:\n",
    "            file = nib.load(out_path)\n",
    "            return file\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error loading registered image from disk for subject {subject_id}, session {session}: {e}\")\n",
    "            raise\n",
    "\n",
    "DataPipe.register_and_convert_to_nifti = register_and_convert_to_nifti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6: `loadImage`\n",
    "Reads an image from disk, registers it to the Harvard-Oxford atlas, and resamples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImage(self, imgPath, subject_id, session):\n",
    "        \"\"\"\n",
    "        Reads an image from a given path, then registers it against the\n",
    "        Harvard-Oxford atlas, returning a NIfTI image resampled to the atlas space.\n",
    "        \n",
    "        Key Steps:\n",
    "        1.\tLoad the Harvard-Oxford Atlas.\n",
    "        2.\tRead the subject’s MRI image.\n",
    "        3.\tRegister the image to the atlas space.\n",
    "        4.\tResample to match the atlas resolution.\n",
    "        \"\"\"\n",
    "        # Path to your local Harvard-Oxford atlas file if needed:\n",
    "        # (Should match what's inside your `fetch_atlas_harvard_oxford` location)\n",
    "        atlasPath = '/Users/mayerunterberg/nilearn_data/fsl/data/atlases/HarvardOxford/HarvardOxford-cort-maxprob-thr25-1mm.nii.gz'\n",
    "        atlas_image = ants.image_read(atlasPath)\n",
    "        ants_img = ants.image_read(imgPath)\n",
    "        \n",
    "        # Register and convert to NIfTI\n",
    "        nifti = self.register_and_convert_to_nifti(\n",
    "            fixed_image=atlas_image,\n",
    "            moving_image=ants_img,\n",
    "            subject_id=subject_id,\n",
    "            session=session\n",
    "        )\n",
    "\n",
    "        # Resample the result to the official atlas image just in case\n",
    "        # (the loaded self.ATLAS_IMAGE might be the same, but we do this \n",
    "        #  to ensure consistent shape/resolution)\n",
    "        img_resampled = resample_to_img(\n",
    "            source_img=nifti,\n",
    "            target_img=self.ATLAS_IMAGE,\n",
    "            force_resample=True,\n",
    "            copy_header=True,\n",
    "            interpolation='nearest'\n",
    "        )\n",
    "        return img_resampled\n",
    "\n",
    "DataPipe.loadImage = loadImage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7: `findDifferingAreasAndVolume`\n",
    "Computes a difference map and calculates mean difference/volume changes per region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findDifferingAreasAndVolume(self, index, img1, img2, threshold=None):\n",
    "        \"\"\"\n",
    "        Given two images, computes the difference map, calculates mean difference\n",
    "        and volume changes per region, and records those metrics in the DataFrame.\n",
    "\n",
    "        •\tComputes difference maps between baseline and follow-up MRI images.\n",
    "        •\tCalculates mean intensity differences in brain regions.\n",
    "        •\tEstimates volume changes per region.\n",
    "        •\tStores results in self.participants_df.\n",
    "        \"\"\"\n",
    "        diff = math_img(\"img1 - img2\", img1=img1, img2=img2)\n",
    "        diff_data = get_data(diff)\n",
    "        \n",
    "        # For volume calculations, get data for each image\n",
    "        img1_data = get_data(img1)\n",
    "        img2_data = get_data(img2)\n",
    "        \n",
    "        # Use the ATLAS_IMAGE affine to find voxel volume\n",
    "        voxel_sizes = np.abs(np.diag(self.ATLAS_IMAGE.affine)[:3])  # shape (3,)\n",
    "        voxel_volume = np.prod(voxel_sizes)  # in mm^3\n",
    "\n",
    "        for label in self.REGION_LABELS:\n",
    "            # region_name from self.LABEL_NAMES\n",
    "            if 0 <= label < len(self.LABEL_NAMES):\n",
    "                region_name = self.LABEL_NAMES[label]\n",
    "            else:\n",
    "                region_name = \"Unknown Region\"\n",
    "                continue\n",
    "            \n",
    "            if region_name in (\"Background\", \"Unknown Region\"):\n",
    "                continue\n",
    "\n",
    "            regionMask = (self.ATLAS_DATA == label)\n",
    "            \n",
    "            # Mean difference in region\n",
    "            regionChanges = diff_data[regionMask]\n",
    "            region_mean_diff = round(float(np.mean(regionChanges)), 2)\n",
    "            \n",
    "            # Volume difference (count of non-zero or above-threshold voxels)\n",
    "            if threshold is not None:\n",
    "                img1_masked = ((img1_data > threshold) & regionMask)\n",
    "                img2_masked = ((img2_data > threshold) & regionMask)\n",
    "            else:\n",
    "                img1_masked = ((img1_data != 0) & regionMask)\n",
    "                img2_masked = ((img2_data != 0) & regionMask)\n",
    "            \n",
    "            # Filters our zero voxels\n",
    "            region_img1_voxels = np.count_nonzero(img1_masked)\n",
    "            region_img2_voxels = np.count_nonzero(img2_masked)\n",
    "            \n",
    "            # Calculates region volume\n",
    "            region_img1_volume = region_img1_voxels * voxel_volume\n",
    "            region_img2_volume = region_img2_voxels * voxel_volume\n",
    "            region_volume_diff = round(region_img1_volume - region_img2_volume, 2)\n",
    "            avgVolume = round((region_img1_volume + region_img2_volume) / 2, 2)\n",
    "            \n",
    "            # Save to the DataFrame\n",
    "            self.participants_df.loc[index, f\"{region_name} Change\"] = region_mean_diff\n",
    "            self.participants_df.loc[index, f\"{region_name} Volume Avg\"] = avgVolume\n",
    "            self.participants_df.loc[index, f\"{region_name} Volume Change\"] = region_volume_diff\n",
    "\n",
    "DataPipe.findDifferingAreasAndVolume = findDifferingAreasAndVolume"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.8: `process_all_subjects`\n",
    "Main loop to load and register images, compute differences, update DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_subjects(self):\n",
    "        \"\"\"\n",
    "        Main loop to process each subject in the participants DataFrame:\n",
    "        1. Iterates through the participant DataFrame.\n",
    "        2. Load baseline and follow-up files.\n",
    "        3. Register them to the atlas space.\n",
    "        4. Compute differences in each region and update participants_df.\n",
    "        \"\"\"\n",
    "        # Loads base files\n",
    "        for idx, row in self.participants_df.iterrows():\n",
    "            baseLinePath = row['Baseline File Path']\n",
    "            followUpPath = row['Followup File Path']\n",
    "            if pd.isna(baseLinePath) or pd.isna(followUpPath):\n",
    "                continue  # skip if missing file\n",
    "            \n",
    "            # Registers files\n",
    "            subject_id = row['participant_id']\n",
    "            baseLine = self.loadImage(baseLinePath, subject_id, 'BL')\n",
    "            followUp = self.loadImage(followUpPath, subject_id, 'FU')\n",
    "            \n",
    "            # Computes differences\n",
    "            self.findDifferingAreasAndVolume(idx, baseLine, followUp)\n",
    "\n",
    "DataPipe.process_all_subjects = process_all_subjects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.9: `display_brain_and_difference`\n",
    "Displays baseline, follow-up, and a difference map side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_brain_and_difference(self, baseline_file, followup_file):\n",
    "        \"\"\"\n",
    "        Purpose:\n",
    "        •\tDisplays baseline, follow-up, and difference images using nilearn.\n",
    "        •\tUses color maps to highlight changes.\n",
    "\n",
    "        Steps:\n",
    "        1.\tLoad the baseline and follow-up MRI images.\n",
    "        2.\tCompute the difference image.\n",
    "        3.\tPlot:\n",
    "        •\tBaseline MRI\n",
    "        •\tFollow-Up MRI\n",
    "        •\tDifference Map (using coolwarm colormap)\n",
    "\n",
    "        \"\"\"\n",
    "        baseline_img = nib.load(baseline_file)\n",
    "        followup_img = nib.load(followup_file)\n",
    "\n",
    "        baseline_data = baseline_img.get_fdata()\n",
    "        followup_data = followup_img.get_fdata()\n",
    "        diff_data = followup_data - baseline_data\n",
    "        diff_img = nib.Nifti1Image(diff_data, affine=baseline_img.affine)\n",
    "\n",
    "        # Plot the difference map\n",
    "        plot_img(diff_img, title=\"Difference MRI\", cmap='coolwarm', colorbar=True)\n",
    "        plt.show()\n",
    "\n",
    "        # Plot the follow-up and baseline images\n",
    "        plot_anat(followup_img, title=\"Follow-Up MRI\")\n",
    "        plot_anat(baseline_img, title=\"Baseline MRI\")\n",
    "        plt.show()\n",
    "\n",
    "DataPipe.display_brain_and_difference = display_brain_and_difference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.10: `display_before_registry`\n",
    "Displays baseline and follow-up images before registration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_before_registry(self, baseline_file, followup_file):\n",
    "        \"\"\"\n",
    "        Displays the brain images for baseline, follow-up, and their difference.\n",
    "        \"\"\"\n",
    "        baseline_img = nib.load(baseline_file)\n",
    "        followup_img = nib.load(followup_file)\n",
    "\n",
    "        # Plot the follow-up and baseline images\n",
    "        plot_img(followup_img, title=\"Follow-Up MRI Before Registry\")\n",
    "        plot_img(baseline_img, title=\"Baseline MRI Before Registry\")\n",
    "        plt.show()\n",
    "\n",
    "DataPipe.display_before_registry = display_before_registry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Conclusion\n",
    "\n",
    "In this notebook, we've outlined how to organize and process neuroimaging data using the `DataPipe` class. The workflow includes:\n",
    "\n",
    "1. **Setting up** file paths and participant metadata.\n",
    "2. **Fetching** and loading the Harvard-Oxford atlas.\n",
    "3. **Registering** subject images to the atlas using ANTs.\n",
    "4. **Computing** volumetric changes and differences in intensity.\n",
    "5. **Visualizing** the results.\n",
    "\n",
    "Feel free to add, remove, or modify the Markdown sections to suit your presentation style."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
