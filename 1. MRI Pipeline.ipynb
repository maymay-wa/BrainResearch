{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ants\n",
    "import xlsxwriter\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nibabel as nib\n",
    "from nilearn.datasets import fetch_atlas_harvard_oxford\n",
    "from nilearn.image import math_img, resample_to_img, get_data, load_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[get_dataset_dir] Dataset found in /Users/mayerunterberg/nilearn_data/fsl\n"
     ]
    }
   ],
   "source": [
    "# Fetch the Harvard-Oxford atlas\n",
    "ATLAS = fetch_atlas_harvard_oxford('cort-maxprob-thr25-1mm')\n",
    "# Load the atlas image\n",
    "ATLAS_IMAGE = image.load_img(ATLAS.maps)\n",
    "ATLAS_DATA = get_data(ATLAS_IMAGE)\n",
    "# Extract region names from the atlas\n",
    "LABEL_NAMES = ATLAS['labels']\n",
    "# Extract unique region labels from the atlas\n",
    "REGION_LABELS = np.unique(ATLAS_DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subject_file_pairs(data_dir, subjectDF):\n",
    "    for subject in os.listdir(data_dir):\n",
    "        subject_path = os.path.join(data_dir, subject)\n",
    "\n",
    "        # Skip non-directories or irrelevant files\n",
    "        if not os.path.isdir(subject_path) or subject.startswith('.') or subject == 'derivatives':\n",
    "            continue\n",
    "\n",
    "        for index, row in subjectDF.iterrows():\n",
    "            subject = row['participant_id']\n",
    "            subject_path = os.path.join(data_dir, f\"sub-{subject:03d}\")\n",
    "\n",
    "            # Locate BL and FU files\n",
    "            baseline_file = os.path.join(subject_path, 'ses-BL', 'anat', f\"sub-{subject:03d}_ses-BL_T1w.nii.gz\")\n",
    "            followup_file = os.path.join(subject_path, 'ses-FU', 'anat', f\"sub-{subject:03d}_ses-FU_T1w.nii.gz\")\n",
    "\n",
    "            # Verify that both files exist\n",
    "            if os.path.exists(baseline_file) and os.path.exists(followup_file):\n",
    "                # Add the file paths to the DataFrame\n",
    "                subjectDF.at[index, 'Baseline File Path'] = 'Data/' + os.path.relpath(baseline_file, data_dir)\n",
    "                subjectDF.at[index, 'Followup File Path'] = 'Data/' + os.path.relpath(followup_file, data_dir)\n",
    "            else:\n",
    "                print(f\"Skipping subject {subject}: missing files.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def register_and_convert_to_nifti(fixed_image, moving_image, subject_id, session, transform_type='Rigid'):\n",
    "    # Construct the output filename\n",
    "    out_path = f\"output/registered_output_sub-{subject_id}_ses-{session}.nii.gz\"\n",
    "    # If the file already exists, just load it and skip registration\n",
    "    if os.path.exists(out_path):\n",
    "        return nib.load(out_path)\n",
    "\n",
    "    # Otherwise performs the registration\n",
    "    registered = ants.registration(\n",
    "        fixed=fixed_image,\n",
    "        moving=moving_image,\n",
    "        type_of_transform=transform_type\n",
    "    )['warpedmovout']\n",
    "    # Write out to disk\n",
    "    out_path = f\"output/registered_output_sub-{subject_id}_ses-{session}.nii.gz\"\n",
    "    ants.image_write(registered, out_path)\n",
    "    return nib.load(out_path)\n",
    "\n",
    "def loadImage(imgPath, subject_id, session):\n",
    "    atlasPath = '/Users/mayerunterberg/nilearn_data/fsl/data/atlases/HarvardOxford/HarvardOxford-cort-maxprob-thr25-1mm.nii.gz'\n",
    "    atlas_image = ants.image_read(atlasPath)\n",
    "    ants_img = ants.image_read(imgPath)\n",
    "    \n",
    "    # Register and convert to NIfTI\n",
    "    nifti = register_and_convert_to_nifti(\n",
    "            fixed_image=atlas_image,\n",
    "            moving_image=ants_img,\n",
    "            subject_id=subject_id,\n",
    "            session=session\n",
    "        )\n",
    "        \n",
    "    img_resampled = resample_to_img(\n",
    "        source_img=nifti,\n",
    "        target_img=ATLAS_IMAGE,\n",
    "        force_resample=True,\n",
    "        copy_header=True,\n",
    "        interpolation='nearest'\n",
    "    )\n",
    "    return img_resampled\n",
    "\n",
    "def findDifferingAreasAndVolume(index, df, img1, img2, threshold=None):\n",
    "    # 1) Create the difference map\n",
    "    diff = image.math_img(\"img1 - img2\", img1=img1, img2=img2)\n",
    "    diff_data = get_data(diff)\n",
    "    \n",
    "    # 2) For volume calculations, get data for each image\n",
    "    img1_data = get_data(img1)\n",
    "    img2_data = get_data(img2)\n",
    "    \n",
    "    # 3) We also need voxel volume, typically from the ATLAS_IMAGEâ€™s affine\n",
    "    # or if each registered image uses the same affine, we can use img1.affine\n",
    "    voxel_sizes = np.abs(np.diag(ATLAS_IMAGE.affine)[:3])  # shape (3,)\n",
    "    voxel_volume = np.prod(voxel_sizes)  # in mm^3\n",
    "    # Loop through each region to compute statistics\n",
    "    for label in REGION_LABELS:\n",
    "        # regionMask indicates voxels belonging to this label\n",
    "        # Determine region name\n",
    "        if 0 <= label < len(LABEL_NAMES):\n",
    "            region_name = LABEL_NAMES[label]\n",
    "        else:\n",
    "            region_name = \"Unknown Region\"\n",
    "            continue\n",
    "        if region_name in (\"Background\"):\n",
    "            continue\n",
    "\n",
    "        regionMask = (ATLAS_DATA == label)\n",
    "        \n",
    "        # A) Mean difference\n",
    "        regionChanges = diff_data[regionMask]\n",
    "        region_mean_diff = round(float(np.mean(regionChanges)), 2)\n",
    "        \n",
    "        # B) Volume difference\n",
    "        # Count nonzero (or > 0) voxels in each image within the region\n",
    "        # In structural MRI, you might need a threshold or binarization approach.\n",
    "        # For a simple approach, let's count all *non-zero* voxels in that region:\n",
    "        if threshold is not None:\n",
    "            img1_masked = (img1_data > threshold) & regionMask\n",
    "            img2_masked = (img2_data > threshold) & regionMask\n",
    "        else:\n",
    "            img1_masked = img1_data != 0 & regionMask\n",
    "            img2_masked = img2_data != 0 & regionMask\n",
    "            \n",
    "        region_img1_voxels = np.count_nonzero(img1_masked)\n",
    "        region_img2_voxels = np.count_nonzero(img2_masked)\n",
    "        \n",
    "        region_img1_volume = region_img1_voxels * voxel_volume\n",
    "        region_img2_volume = region_img2_voxels * voxel_volume\n",
    "        region_volume_diff = round(region_img1_volume - region_img2_volume, 2)\n",
    "        \n",
    "        # Save to the DataFrame\n",
    "        df.loc[index, f\"{region_name} Change\"] = region_mean_diff\n",
    "        df.loc[index, f\"{region_name} Volume Change\"] = region_volume_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants_df = pd.read_csv('Data/participants.tsv', sep=\"\\t\")\n",
    "# Add columns for file paths\n",
    "# Prepare all the new column names\n",
    "new_cols = {}\n",
    "filePaths = ['Baseline File Path', 'Followup File Path']\n",
    "for label in filePaths:\n",
    "    new_cols[f\"{label}\"] = [None]*len(participants_df)\n",
    "for label in LABEL_NAMES:\n",
    "    if label in (\"Background\", \"Unknown Region\"):\n",
    "        continue\n",
    "    new_cols[f\"{label} Volume Change\"] = [None]*len(participants_df)\n",
    "for label in LABEL_NAMES:\n",
    "    if label in (\"Background\", \"Unknown Region\"):\n",
    "        continue\n",
    "    new_cols[f\"{label} Change\"] = [None]*len(participants_df)\n",
    "\n",
    "# Create an empty DataFrame with those columns\n",
    "columns_df = pd.DataFrame(new_cols, index=participants_df.index)\n",
    "\n",
    "# Concatenate horizontally (axis=1)\n",
    "participants_df = pd.concat([participants_df, columns_df], axis=1)\n",
    "get_subject_file_pairs('Data', participants_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, row in participants_df.iterrows():\n",
    "    baseLinePath = row['Baseline File Path']\n",
    "    followUpPath = row['Followup File Path']\n",
    "    if pd.isna(baseLinePath) or pd.isna(followUpPath):\n",
    "        continue  # skip if missing file\n",
    "    baseLine = loadImage(baseLinePath, row['participant_id'], 'BL')\n",
    "    followUp = loadImage(followUpPath, row['participant_id'], 'FU')\n",
    "    findDifferingAreasAndVolume(idx, participants_df, baseLine, followUp, 10)\n",
    "    \n",
    "#participants_df = participants_df.drop(columns=['Baseline File Path', 'Followup File Path'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['open', 'participants_with_changes.xlsx'], returncode=0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "output_excel_path = 'participants_with_changes.xlsx'\n",
    "\n",
    "# Use the XlsxWriter engine so we can format cells\n",
    "with pd.ExcelWriter(output_excel_path, engine='xlsxwriter') as writer:\n",
    "    participants_df.to_excel(writer, index=False, sheet_name='Sheet1')\n",
    "    workbook = writer.book\n",
    "    worksheet = writer.sheets['Sheet1']\n",
    "    cell_format = workbook.add_format({\n",
    "        'font_size': 14,\n",
    "        'align': 'center',\n",
    "        'valign': 'vcenter'\n",
    "    })\n",
    "    for col_num, col_name in enumerate(participants_df.columns):\n",
    "        column_data = participants_df[col_name].astype(str)\n",
    "        max_len = max(column_data.map(len).max(), len(col_name))\n",
    "        worksheet.set_column(col_num, col_num, max_len + 2, cell_format)\n",
    "subprocess.run([\"open\", output_excel_path])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "participants_df['avg cudit'] = (participants_df['cudit total baseline'] + participants_df['cudit total follow-up']) / 2\n",
    "cudit_columns = ['avg cudit']\n",
    "brain_region_columns = [col for col in participants_df.columns if 'Change' in col]\n",
    "# Combine into one dataset\n",
    "correlation_data = participants_df[cudit_columns + brain_region_columns]\n",
    "# Compute correlations\n",
    "correlation_matrix = correlation_data.corr()\n",
    "cudit_correlations = correlation_matrix.loc[cudit_columns, brain_region_columns]\n",
    "#cudit_correlations.T.sort_values(by='avg cudit', ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
